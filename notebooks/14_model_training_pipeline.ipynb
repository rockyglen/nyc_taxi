{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05 16:30:08,565 INFO: Initializing external client\n",
      "2025-03-05 16:30:08,566 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-05 16:30:16,070 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215683\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME, api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "feature_store = project.get_feature_store()\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1215683/fs/1203307/fv/time_series_hourly_feature_view/version/1\n",
      "Feature view 'time_series_hourly_feature_view' (version 1) created successfully.\n",
      "Feature view 'time_series_hourly_feature_view' (version 1) retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a feature view if it doesn't already exist\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view '{config.FEATURE_VIEW_NAME}' (version {config.FEATURE_VIEW_VERSION}) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "# Retrieve the feature view\n",
    "try:\n",
    "    feature_view = feature_store.get_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "    )\n",
    "    print(f\"Feature view '{config.FEATURE_VIEW_NAME}' (version {config.FEATURE_VIEW_VERSION}) retrieved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving feature view: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data, _ = feature_view.training_data(\n",
    "    description=\"Time-series hourly taxi rides\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.sort_values([\"pickup_location_id\", \"pickup_hour\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"pickup_hour\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"pickup_hour\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ts_data[\"pickup_hour\"] = pd.to_datetime(ts_data[\"pickup_hour\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)  # Remove timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"year_month\"] = ts_data[\"pickup_hour\"].dt.to_period(\"M\")  # Year-Month format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by year_month and count\n",
    "hour_counts = ts_data.groupby(\"year_month\").size()\n",
    "\n",
    "# Plot the data\n",
    "ax = hour_counts.plot(kind=\"bar\", figsize=(10, 6), color=\"skyblue\", edgecolor=\"black\")  # Use 'ax' to store the plot object\n",
    "ax.set_title(\"Number of Hours by Year/Month\", fontsize=16)\n",
    "ax.set_xlabel(\"Year-Month\", fontsize=12)\n",
    "ax.set_ylabel(\"Count of Hours\", fontsize=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gte = ts_data[\"year_month\"] >= pd.Period(\"2023-01\", freq=\"M\")\n",
    "lte = ts_data[\"year_month\"] <= pd.Period(\"2023-12\", freq=\"M\")\n",
    "cond = gte & lte\n",
    "filtered_data = ts_data[cond].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.drop(columns=[\"year_month\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_ts_data_info_features_and_target\n",
    "\n",
    "features, targets = transform_ts_data_info_features_and_target(ts_data, window_size=24*28, step_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_values([\"pickup_location_id\", \"pickup_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_copy = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_targets = features.copy()\n",
    "features_targets[\"target\"] = targets\n",
    "\n",
    "features_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.data_utils import split_time_series_data\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.Timestamp(\"2023-01-01\")\n",
    "end_date = pd.Timestamp(\"2023-12-31\")\n",
    "\n",
    "# Calculate the total number of days in the date range\n",
    "total_days = (end_date - start_date).days + 1\n",
    "\n",
    "# Calculate the cutoff date for 80% training data\n",
    "cutoff_days = int(total_days * 0.8)\n",
    "cutoff_date = start_date + pd.Timedelta(days=cutoff_days)\n",
    "\n",
    "cutoff_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_time_series_data(\n",
    "    features_targets,\n",
    "    cutoff_date=cutoff_date,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'lgbmregressor__n_estimators': [100, 200, 300],\n",
    "    'lgbmregressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'lgbmregressor__max_depth': [3, 5, 7],\n",
    "    'lgbmregressor__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'lgbmregressor__subsample': [0.8, 0.9, 1.0],\n",
    "    'lgbmregressor__reg_alpha': [0, 0.1, 0.5],\n",
    "    'lgbmregressor__reg_lambda': [0, 0.1, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline_utils import get_pipeline\n",
    "pipeline = get_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV object\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    scoring='neg_mean_absolute_error',  # Use negative MAE for scoring (as GridSearchCV maximizes the score)\n",
    "    cv=3,  # Cross-validation folds\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best negative MAE score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# --- 7. Evaluate the Best Model ---\n",
    "predictions = best_model.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Test MAE with the best model: {test_mae:.4f}\")\n",
    "\n",
    "# --- 8. Model Registry and Saving ---\n",
    "# Save the best model\n",
    "joblib.dump(best_model, config.MODELS_DIR / \"lgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(features)\n",
    "output_schema = Schema(targets)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = project.get_model_registry()\n",
    "\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"taxi_demand_predictor_next_hour\",\n",
    "    metrics={\"test_mae\": test_mae},\n",
    "    description=\"LightGBM regressor\",\n",
    "    input_example=features.sample(),\n",
    "    model_schema=model_schema,\n",
    "      \n",
    ")\n",
    "# https://community.hopsworks.ai/t/attributeerror-windowspath-object-has-no-attribute-startswith/1003\n",
    "# model.save(config.MODELS_DIR / 'lgb_model.pkl')\n",
    "model.save(\"D:/Taxi_Project/nyc_taxi/models/lgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import load_model_from_registry\n",
    "\n",
    "model = load_model_from_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import get_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_model_predictions(model, features_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = mean_absolute_error(targets, preds[\"predicted_demand\"])\n",
    "print(f\"{test_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
